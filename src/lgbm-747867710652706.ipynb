{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  v0 code ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta \n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "import pdb\n",
    "train = pd.read_csv('../input/av-wns-hack/train_na17sgz/train.csv')\n",
    "test = pd.read_csv('../input/av-wns-hack/test_aq1fgdb/test.csv')\n",
    "log = pd.read_csv('../input/av-wns-hack/train_na17sgz/view_log.csv')\n",
    "item = pd.read_csv('../input/av-wns-hack/train_na17sgz/item_data.csv')\n",
    "\n",
    "train['impression_time'] = pd.to_datetime(train['impression_time'])\n",
    "test['impression_time'] = pd.to_datetime(test['impression_time'])\n",
    "display(train.head(),test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### does not assume that no two time periods for the same \n",
    "\n",
    "def getRRByCategory(train,test,category,dvalueDiff,trace=False,limit=True):\n",
    "    print(\"Category:{}\".format(category))\n",
    "    if limit:\n",
    "        LL = limit\n",
    "    else:\n",
    "        LL = 'NoLimit'\n",
    "        dvalueDiff = 0\n",
    "\n",
    "    train['BeforeRunRate_{}_{}_{}'.format(category,LL,dvalueDiff)] = -999\n",
    "    test['BeforeRunRate_{}_{}_{}'.format(category,LL,dvalueDiff)] = -999\n",
    "    testMiss = [] ### for things that are not in test\n",
    "    if trace:\n",
    "            pdb.set_trace()\n",
    "    for _uq in tqdm_notebook(train[category].unique()):\n",
    "        _i = train[train[category]==_uq].index\n",
    "        _i1 = test[test[category]==_uq].index\n",
    "        _tt =  train.loc[_i,'impression_time']\n",
    "        _tt1 = test.loc[_i1,'impression_time']\n",
    "        #print(\"Starting test loop\")\n",
    "        for time in np.unique(_tt1.values):\n",
    "            if limit:\n",
    "                dd = pd.to_datetime(time).day\n",
    "                increment = dd-12\n",
    "                diff = pd.to_datetime(time)-timedelta(days=dvalueDiff+increment)\n",
    "                IdxBool = (_tt>=diff) & (_tt<time)\n",
    "            else:\n",
    "                #print(\"aaaa\")\n",
    "                IdxBool = (_tt<time)\n",
    " \n",
    "            IdxBoolffill = _tt1[_tt1==time].index\n",
    "            \n",
    "            try:\n",
    "                sub = _tt[IdxBool]\n",
    "                meanRRBefore = train.loc[sub.index,'is_click'].mean()\n",
    "                if np.isnan(meanRRBefore):\n",
    "                    meanRRBefore = -999\n",
    "                test.loc[IdxBoolffill,'BeforeRunRate_{}_{}_{}'.format(category,LL,dvalueDiff)] = meanRRBefore            \n",
    "            except:\n",
    "                meanRRBefore = -999\n",
    "                test.loc[IdxBoolffill,'BeforeRunRate_{}_{}_{}'.format(category,LL,dvalueDiff)] = meanRRBefore        \n",
    "                testMiss.append(_uq)\n",
    "        #print(\"Starting train loop\")\n",
    "        for time in np.unique(_tt.values):\n",
    "            if limit:\n",
    "                diff = pd.to_datetime(time)-timedelta(days=dvalueDiff)\n",
    "                IdxBool = (_tt>=diff) & (_tt<time)\n",
    "            else:\n",
    "                IdxBool = (_tt<time)\n",
    " \n",
    "            IdxBoolffill = _tt[_tt==time].index\n",
    "            try:\n",
    "                sub = _tt[IdxBool]\n",
    "                meanRRBefore = train.loc[sub.index,'is_click'].mean()\n",
    "                if np.isnan(meanRRBefore):\n",
    "                    meanRRBefore = -999\n",
    "            except:\n",
    "                meanRRBefore = -999\n",
    "                testMiss.append(_uq)\n",
    "            train.loc[IdxBoolffill,'BeforeRunRate_{}_{}_{}'.format(category,LL,dvalueDiff)] = meanRRBefore\n",
    "        #print(\"-------\")\n",
    "    return train,test,testMiss\n",
    "\n",
    "train,test,testMissInit = getRRByCategory(train,test,'app_code',dvalueDiff=8,trace=False,limit=False)\n",
    "\n",
    "for values in tqdm_notebook([7,14,21]):\n",
    "    train,test,testMissFinal = getRRByCategory(train,test,'app_code',dvalueDiff=values,trace=False,limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"trainWithRRstats_v0.csv\",index=False)\n",
    "test.to_csv(\"testWithRRstats_v0.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v1 code ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta \n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "import pdb\n",
    "train = pd.read_csv('../input/av-wns-hack/train_na17sgz/train.csv')\n",
    "test = pd.read_csv('../input/av-wns-hack/test_aq1fgdb/test.csv')\n",
    "log = pd.read_csv('../input/av-wns-hack/train_na17sgz/view_log.csv')\n",
    "item = pd.read_csv('../input/av-wns-hack/train_na17sgz/item_data.csv')\n",
    "\n",
    "train['impression_time'] = pd.to_datetime(train['impression_time'])\n",
    "test['impression_time'] = pd.to_datetime(test['impression_time'])\n",
    "display(train.head(),test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### does not assume that no two time periods for the same \n",
    "\n",
    "def getRRByCategory(train,test,category,dvalueDiff,trace=False,limit=True):\n",
    "    print(\"Category:{}\".format(category))\n",
    "    if limit:\n",
    "        LL = limit\n",
    "    else:\n",
    "        LL = 'NoLimit'\n",
    "        dvalueDiff = 0\n",
    "        \n",
    "    train['BeforeRunRate_{}_{}_{}'.format(category,LL,dvalueDiff)] = -999\n",
    "    test['BeforeRunRate_{}_{}_{}'.format(category,LL,dvalueDiff)] = -999\n",
    "    testMiss = [] ### for things that are not in test\n",
    "    if trace:\n",
    "            pdb.set_trace()\n",
    "    for _uq in tqdm_notebook(train[category].unique()):\n",
    "        _i = train[train[category]==_uq].index\n",
    "        _i1 = test[test[category]==_uq].index\n",
    "        _tt =  train.loc[_i,'impression_time']\n",
    "        _tt1 = test.loc[_i1,'impression_time']\n",
    "        #print(\"Starting test loop\")\n",
    "        for time in np.unique(_tt1.values):\n",
    "            if limit:\n",
    "                dd = pd.to_datetime(time).day\n",
    "                increment = dd-12\n",
    "                diff = pd.to_datetime(time)-timedelta(days=dvalueDiff+increment)\n",
    "                IdxBool = (_tt>=diff) & (_tt<time)\n",
    "            else:\n",
    "                #print(\"aaaa\")\n",
    "                IdxBool = (_tt<time)\n",
    " \n",
    "            IdxBoolffill = _tt1[_tt1==time].index\n",
    "            \n",
    "            try:\n",
    "                sub = _tt[IdxBool]\n",
    "                meanRRBefore = train.loc[sub.index,'is_click'].mean()\n",
    "                if np.isnan(meanRRBefore):\n",
    "                    meanRRBefore = -999\n",
    "                test.loc[IdxBoolffill,'BeforeRunRate_{}_{}_{}'.format(category,LL,dvalueDiff)] = meanRRBefore            \n",
    "            except:\n",
    "                meanRRBefore = -999\n",
    "                test.loc[IdxBoolffill,'BeforeRunRate_{}_{}_{}'.format(category,LL,dvalueDiff)] = meanRRBefore        \n",
    "                testMiss.append(_uq)\n",
    "        #print(\"Starting train loop\")\n",
    "        for time in np.unique(_tt.values):\n",
    "            if limit:\n",
    "                diff = pd.to_datetime(time)-timedelta(days=dvalueDiff)\n",
    "                IdxBool = (_tt>=diff) & (_tt<time)\n",
    "            else:\n",
    "                IdxBool = (_tt<time)\n",
    " \n",
    "            IdxBoolffill = _tt[_tt==time].index\n",
    "            try:\n",
    "                sub = _tt[IdxBool]\n",
    "                meanRRBefore = train.loc[sub.index,'is_click'].mean()\n",
    "                if np.isnan(meanRRBefore):\n",
    "                    meanRRBefore = -999\n",
    "            except:\n",
    "                meanRRBefore = -999\n",
    "                testMiss.append(_uq)\n",
    "            train.loc[IdxBoolffill,'BeforeRunRate_{}_{}_{}'.format(category,LL,dvalueDiff)] = meanRRBefore\n",
    "        #print(\"-------\")\n",
    "    return train,test,testMiss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['app_code_os_version'] = train['app_code'].astype(str)+\"_\"+train['os_version']\n",
    "test['app_code_os_version'] = test['app_code'].astype(str)+\"_\"+test['os_version']\n",
    "\n",
    "train['user_id_app_code'] = train['user_id'].astype(str)+\"_\"+train['app_code'].astype(str)\n",
    "test['user_id_app_code'] = test['user_id'].astype(str)+\"_\"+test['app_code'].astype(str)\n",
    "for values in tqdm_notebook(['app_code_os_version','user_id_app_code']):\n",
    "    train,test,testMissFinal = getRRByCategory(train,test,values,dvalueDiff=1,trace=False,limit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.to_csv(\"trainWithRRstatsMore.csv\",index=False)\n",
    "# test.to_csv(\"testWithRRstatsMore.csv\",index=False)\n",
    "train.to_csv(\"trainWithRRstats_v1.csv\",index=False)\n",
    "test.to_csv(\"testWithRRstats_v1.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v2 code ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/av-wns-hack/train_na17sgz/train.csv')\n",
    "test = pd.read_csv('../input/av-wns-hack/test_aq1fgdb/test.csv')\n",
    "log = pd.read_csv('../input/av-wns-hack/train_na17sgz/view_log.csv')\n",
    "item = pd.read_csv('../input/av-wns-hack/train_na17sgz/item_data.csv')\n",
    "\n",
    "train['impression_time'] = pd.to_datetime(train['impression_time'])\n",
    "test['impression_time'] = pd.to_datetime(test['impression_time'])\n",
    "display(train.head(),test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### does not assume that no two time periods for the same \n",
    "\n",
    "def getRRByCategory(train,test,category,dvalueDiff,trace=False,limit=True):\n",
    "    print(\"Category:{}\".format(category))\n",
    "    if limit:\n",
    "        LL = limit\n",
    "    else:\n",
    "        LL = 'NoLimit'\n",
    "        dvalueDiff = 0\n",
    "        \n",
    "    train['BeforeRunRate_{}_{}_{}'.format(category,LL,dvalueDiff)] = -999\n",
    "    test['BeforeRunRate_{}_{}_{}'.format(category,LL,dvalueDiff)] = -999\n",
    "    testMiss = [] ### for things that are not in test\n",
    "    if trace:\n",
    "            pdb.set_trace()\n",
    "    for _uq in tqdm_notebook(train[category].unique()):\n",
    "        _i = train[train[category]==_uq].index\n",
    "        _i1 = test[test[category]==_uq].index\n",
    "        _tt =  train.loc[_i,'impression_time']\n",
    "        _tt1 = test.loc[_i1,'impression_time']\n",
    "        #print(\"Starting test loop\")\n",
    "        for time in np.unique(_tt1.values):\n",
    "            if limit:\n",
    "                dd = pd.to_datetime(time).day\n",
    "                increment = dd-12\n",
    "                diff = pd.to_datetime(time)-timedelta(days=dvalueDiff+increment)\n",
    "                IdxBool = (_tt>=diff) & (_tt<time)\n",
    "            else:\n",
    "                #print(\"aaaa\")\n",
    "                IdxBool = (_tt<time)\n",
    " \n",
    "            IdxBoolffill = _tt1[_tt1==time].index\n",
    "            \n",
    "            try:\n",
    "                sub = _tt[IdxBool]\n",
    "                meanRRBefore = train.loc[sub.index,'is_click'].mean()\n",
    "                if np.isnan(meanRRBefore):\n",
    "                    meanRRBefore = -999\n",
    "                test.loc[IdxBoolffill,'BeforeRunRate_{}_{}_{}'.format(category,LL,dvalueDiff)] = meanRRBefore            \n",
    "            except:\n",
    "                meanRRBefore = -999\n",
    "                test.loc[IdxBoolffill,'BeforeRunRate_{}_{}_{}'.format(category,LL,dvalueDiff)] = meanRRBefore        \n",
    "                testMiss.append(_uq)\n",
    "        #print(\"Starting train loop\")\n",
    "        for time in np.unique(_tt.values):\n",
    "            if limit:\n",
    "                diff = pd.to_datetime(time)-timedelta(days=dvalueDiff)\n",
    "                IdxBool = (_tt>=diff) & (_tt<time)\n",
    "            else:\n",
    "                IdxBool = (_tt<time)\n",
    " \n",
    "            IdxBoolffill = _tt[_tt==time].index\n",
    "            try:\n",
    "                sub = _tt[IdxBool]\n",
    "                meanRRBefore = train.loc[sub.index,'is_click'].mean()\n",
    "                if np.isnan(meanRRBefore):\n",
    "                    meanRRBefore = -999\n",
    "            except:\n",
    "                meanRRBefore = -999\n",
    "                testMiss.append(_uq)\n",
    "            train.loc[IdxBoolffill,'BeforeRunRate_{}_{}_{}'.format(category,LL,dvalueDiff)] = meanRRBefore\n",
    "        #print(\"-------\")\n",
    "    return train,test,testMiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['app_code_os_version'] = train['app_code'].astype(str)+\"_\"+train['os_version']\n",
    "test['app_code_os_version'] = test['app_code'].astype(str)+\"_\"+test['os_version']\n",
    "\n",
    "train['user_id_app_code'] = train['user_id'].astype(str)+\"_\"+train['app_code'].astype(str)\n",
    "test['user_id_app_code'] = test['user_id'].astype(str)+\"_\"+test['app_code'].astype(str)\n",
    "for j in ([7,14,21]):\n",
    "    train,test,testMissFinal = getRRByCategory(train,test,'app_code_os_version',dvalueDiff=j,trace=False,limit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.to_csv(\"trainWithRRstatsMore.csv\",index=False)\n",
    "# test.to_csv(\"testWithRRstatsMore.csv\",index=False)\n",
    "train.to_csv(\"trainWithRRstats_v2.csv\",index=False)\n",
    "test.to_csv(\"testWithRRstats_v2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  log merge approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Path = '../input/av-wns-hack/train_na17sgz/'\n",
    "Test_Path = '../input/av-wns-hack/test_aq1fgdb/'\n",
    "train = pd.read_csv(os.path.join(Train_Path,'train.csv'))\n",
    "log = pd.read_csv(os.path.join(Train_Path,'view_log.csv'))\n",
    "item = pd.read_csv(os.path.join(Train_Path,'item_data.csv'))\n",
    "test = pd.read_csv(os.path.join(Test_Path,'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import datetime\n",
    "def timer(tag_name):\n",
    "    def timer_decorator(fn):\n",
    "        def _fn(*args, **kwargs):\n",
    "            s = datetime.datetime.now()\n",
    "            output = fn(*args, **kwargs)\n",
    "            e = datetime.datetime.now()\n",
    "            print('[{}] {} completed in {}'.format(tag_name, fn.__name__, e - s))\n",
    "            return output\n",
    "\n",
    "        return _fn\n",
    "\n",
    "    return timer_decorator\n",
    "\n",
    "@timer(\"datetime conversion\")\n",
    "def convertDTZone(df,col='impression_time'):\n",
    "    df[col] = pd.to_datetime(df[col])\n",
    "    return df\n",
    "\n",
    "train = convertDTZone(train,col='impression_time')\n",
    "log = convertDTZone(log,col='server_time')\n",
    "test = convertDTZone(test,col='impression_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timer(\"Generate base datetime featues\")\n",
    "def genDateTimeFeats(df,col='impression_time'):\n",
    "    df[col+\"_day\"] = df[col].dt.day\n",
    "    df[col+\"_minute\"]=df[col].dt.minute\n",
    "    df[col+\"_second\"]=df[col].dt.second\n",
    "    df[col+\"_second\"]=df[col].dt.month\n",
    "    return df\n",
    "\n",
    "train = genDateTimeFeats(train)\n",
    "log = genDateTimeFeats(log,'server_time')\n",
    "test = genDateTimeFeats(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTDStats(TD):\n",
    "    totsec = TD.total_seconds()\n",
    "    h = totsec//3600\n",
    "    m = (totsec%3600) // 60\n",
    "    sec =(totsec%3600)%60 #just for reference\n",
    "    return h,m\n",
    "def getTDStatsD(TD):\n",
    "    totsec = TD.total_seconds()\n",
    "    h = totsec//3600\n",
    "    m = (totsec%3600) // 60\n",
    "    sec =(totsec%3600)%60 #just for reference\n",
    "    return h\n",
    "def getTDStatsM(TD):\n",
    "    totsec = TD.total_seconds()\n",
    "    h = totsec//3600\n",
    "    m = (totsec%3600) // 60\n",
    "    sec =(totsec%3600)%60 #just for reference\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "import pdb\n",
    "from tqdm import tqdm_notebook,tqdm\n",
    "@timer('Log present H hours b4 the adv click')\n",
    "def getLogPresentIndicator(df,log,threshold = 10):\n",
    "    df[\"LogPresent_{}_hour_before\".format(threshold)] = 0\n",
    "    df[\"Count_LogPresent_{}_hour_before\".format(threshold)] = 0\n",
    "    for uID,uDF in tqdm_notebook(df[['user_id','impression_time']].groupby(by='user_id')):\n",
    "        #pdb.set_trace()\n",
    "        temp = log.loc[log['user_id']==uID,:]\n",
    "        adArr = pd.to_datetime(uDF['impression_time'])\n",
    "        logArr = pd.to_datetime(temp['server_time'])\n",
    "        for qpt in adArr: ### we need to check time of ad impression > h hours from time of log impression\n",
    "            idxQpt = adArr[adArr==qpt].index\n",
    "            diff = (qpt - logArr) ## we need diff> 0 only for now and les than someting say 1 hour\n",
    "            nullTD = datetime.timedelta(0)\n",
    "            try:\n",
    "                cut1,m = diff[diff>nullTD],min(diff[diff>nullTD])\n",
    "                hour,mins = getTDStats(m)\n",
    "                H = cut1.apply(getTDStatsD)\n",
    "                M =  cut1.apply(getTDStatsM)\n",
    "                c = H[(H>=0) & (H < threshold)].index\n",
    "                c1 = M[M>=0][c]\n",
    "                print(\"prelim stats\",cut1.shape[0],hour,mins)\n",
    "                if ((cut1.shape[0] != [])  and (hour >= 0) and (hour < threshold) \n",
    "                    and (mins>=0)):\n",
    "                    print(\"shape\",cut1.shape[0])\n",
    "                    df.loc[idxQpt,\"LogPresent_{}_hour_before\".format(threshold)] = 1\n",
    "                    df.loc[idxQpt,\"Count_LogPresent_{}_hour_before\".format(threshold)] = c1.shape[0]\n",
    "                    print(\"Success\")\n",
    "            except:\n",
    "                print(\"diff is null vector\")   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for th in [1,8,12]:   ### 1 can be used for qc, all vals in test will be 0 when th = 1 \n",
    "    train = getLogPresentIndicator(train,log,th*24)\n",
    "    test = getLogPresentIndicator(test,log,th*24)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train.csv',index=False)\n",
    "test.to_csv('test.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### merge log approx code ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path_consol = '../input/wns-hack-v0'\n",
    "Path_raw = '../input/av-wns-hack/train_na17sgz'\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "log = pd.read_csv(os.path.join(Path_raw,'view_log.csv'))\n",
    "item = pd.read_csv(os.path.join(Path_raw,'item_data.csv'))\n",
    "\n",
    "@timer(\"Left Merge\")\n",
    "def merge(df1,df2,onCol):\n",
    "    return pd.merge(df1,df2,on=onCol,how='left')\n",
    "### merge item details with log\n",
    "log = merge(log,item,'item_id')\n",
    "log.head()\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "import pdb\n",
    "\n",
    "@timer('merge from log approximately')\n",
    "def getMergeFromLog(df,log):\n",
    "    name = \"NearestLog_\"\n",
    "    df.loc[:,name+\"server_time\"] = 0\n",
    "#     df.loc[:,name+\"device_type_0\"] = 'Missing'\n",
    "    df.loc[:,name+\"user_id\"] = 'Missing'  ### for QC\n",
    "#     df.loc[:,name+\"item_id\"] = 'Missing'\n",
    "\n",
    "    for uID,uDF in tqdm_notebook(df[['user_id','impression_time']].groupby(by='user_id')):\n",
    "#         pdb.set_trace()\n",
    "        temp = log.loc[log['user_id']==uID,:]\n",
    "        adArr = pd.to_datetime(uDF['impression_time'])\n",
    "        logArr = pd.to_datetime(temp['server_time'])\n",
    "        for qpt in adArr:\n",
    "            idxQpt = adArr[adArr==qpt].index\n",
    "            diff = (qpt - logArr)\n",
    "            diff.index = logArr.index = temp.index\n",
    "            nullTD = datetime.timedelta(0)\n",
    "            if len(diff[diff>nullTD]) >= 1:\n",
    "                try:\n",
    "                    cut1,m = diff[diff>nullTD],min(diff[diff>nullTD])\n",
    "                    mIDx = (cut1[cut1==m].index)\n",
    "                    potentialLogRows = temp[temp.index.isin(mIDx)]               \n",
    "                    df.loc[idxQpt,name+\"server_time\"] = potentialLogRows['server_time'].values[0] ### has to be same as min value is same\n",
    "                    df.loc[idxQpt,name+\"user_id\"] = potentialLogRows['user_id'].values[0]  ### for QC, should be same\n",
    "                    for t in range(len(potentialLogRows['device_type'].values.astype(list))):\n",
    "                        df.loc[idxQpt,name+\"device_type_{}\".format(t)] = potentialLogRows['device_type'].values.astype(list)[t]\n",
    "                        df.loc[idxQpt,name+\"item_id_{}\".format(t)] = potentialLogRows['item_id'].values.astype(list)[t]\n",
    "                    #print(\"Success\")\n",
    "                except:\n",
    "                    cut1,m = diff[diff>nullTD],min(diff[diff>nullTD])\n",
    "                    mIDx = (cut1[cut1==m].index)\n",
    "                    print(\"earlier\",mIDx)\n",
    "                    print(mIDx)\n",
    "                    potentialLogRows = temp[temp.index.isin(mIDx)]\n",
    "                    print(potentialLogRows,\"Null diff shape\")\n",
    "    return df\n",
    "\n",
    "train_new = getMergeFromLog(train,log)\n",
    "test_new = getMergeFromLog(test,log)\n",
    "\n",
    "train_new.to_csv('trainWithLogMergeApprox.csv',index=False)\n",
    "test_new.to_csv('testWithLogMergeApprox.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### back to morecountfe part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('trainWithLogMergeApprox.csv')\n",
    "test = pd.read_csv('testWithLogMergeApprox.csv')\n",
    "\n",
    "###\n",
    "target = train['is_click']\n",
    "c = [i for i in train.columns if i in test.columns]\n",
    "train = train[c]\n",
    "test = test[c]\n",
    "\n",
    "train.fillna(-99,inplace=True)\n",
    "test.fillna(-99,inplace=True)\n",
    "\n",
    "badIdxTr = train[train['NearestLog_server_time']=='0']['NearestLog_server_time'].index\n",
    "badIdxTe = test[test['NearestLog_server_time']=='0']['NearestLog_server_time'].index\n",
    "train.loc[badIdxTr,'NearestLog_server_time'] = '2018-01-01 00:00:00'\n",
    "test.loc[badIdxTe,'NearestLog_server_time'] = '2018-01-01 00:00:00'\n",
    "\n",
    "def getTimeDelta(train,test):\n",
    "    trTD = (pd.to_datetime(train['impression_time']) -pd.to_datetime(train['NearestLog_server_time']))\n",
    "    teTD = (pd.to_datetime(test['impression_time']) -pd.to_datetime(test['NearestLog_server_time']))\n",
    "    train['TD_Days']=trTD.dt.days\n",
    "    train['TD_Hours']=(trTD.dt.seconds)//3600\n",
    "    train['TD_Mins']=(trTD.dt.seconds//60)%60\n",
    "    test['TD_Days']=teTD.dt.days\n",
    "    test['TD_Hours']=(teTD.dt.seconds)//3600\n",
    "    test['TD_Mins']=(teTD.dt.seconds//60)%60\n",
    "    return train,test\n",
    "\n",
    "train,test = getTimeDelta(train,test)\n",
    "def converttoDT(train,test):\n",
    "    train['impression_time'] = pd.to_datetime(train['impression_time'])\n",
    "    test['impression_time'] = pd.to_datetime(test['impression_time'])\n",
    "    test['NearestLog_server_time'] = pd.to_datetime(test['NearestLog_server_time'])\n",
    "    train['NearestLog_server_time'] = pd.to_datetime(train['NearestLog_server_time'])\n",
    "    return train,test\n",
    "\n",
    "train,test = converttoDT(train,test)\n",
    "\n",
    "def getCountImpressionPrevDHour(minsArr,D):\n",
    "    casdt = list()\n",
    "    casdt.append(0)\n",
    "    for i in range(len(minsArr)):\n",
    "        if i == 0:\n",
    "            pass\n",
    "        elif i == 1:\n",
    "            casdt.append(((minsArr[1]-minsArr[0])<D).astype(int))\n",
    "        elif i > 1:\n",
    "            i += 1\n",
    "            newArr = minsArr[:i]\n",
    "            cumsum = np.cumsum(newArr)\n",
    "            res = cumsum[-1]-cumsum[:-1]\n",
    "            res = np.sum(res<D)\n",
    "            casdt.append(res)\n",
    "    return pd.Series(casdt)\n",
    "\n",
    "def getImpressionCounts(df,col):\n",
    "    df[col+'_timeSinceLastImpressionMins'] = 0\n",
    "    df[col+'_AvgtimeForLastImpressionMins'] = 0\n",
    "    df[col+'_StdtimeForLastImpressionMins'] = 0\n",
    "    df[col+'_NCountImpressions'] = 0\n",
    "    for uq in tqdm(df[col].unique()):\n",
    "        temp = df[df[col]==uq]['impression_time'].sort_values()\n",
    "        shift = temp.shift(1)\n",
    "        diff = (temp.values-temp.shift(1,fill_value=temp.values.min()).values)\n",
    "        minsArr = diff.astype('timedelta64[m]') / np.timedelta64(1, 'm')\n",
    "        df.loc[temp.index,col+'_timeSinceLastImpressionMins'] = np.array(minsArr)\n",
    "        df.loc[temp.index,col+'_AvgtimeForLastImpressionMins'] = np.mean(minsArr)\n",
    "        df.loc[temp.index,col+'_StdtimeForLastImpressionMins'] = np.std(minsArr)\n",
    "        df.loc[temp.index,col+'_NCountImpressions'] = len(temp)\n",
    "    return df\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "def getCountinLastDMins(df,col,D=[60,120]):\n",
    "    for d in D:\n",
    "        df['{}_CountInLast_{}_MinsImpression'.format(col,d)] = 0\n",
    "    for uq in tqdm(df[col].unique()):\n",
    "        temp = df[df[col]==uq]['impression_time'].sort_values()\n",
    "        shift = temp.shift(1)\n",
    "        diff = (temp.values-temp.shift(1,fill_value=temp.values.min()).values)\n",
    "        minsArr = diff.astype('timedelta64[m]') / np.timedelta64(1, 'm')\n",
    "        for d in D:\n",
    "            df.loc[temp.index,'{}_CountInLast_{}_MinsImpression'.format(col,d)] = getCountImpressionPrevDHour(minsArr,d).values\n",
    "    return df\n",
    "consol = pd.concat([train,test],0)\n",
    "consol.reset_index(inplace=True,drop=True)\n",
    "consol.head()\n",
    "\n",
    "from tqdm import tqdm\n",
    "D=[60,120,300,600,24*60,24*60*2,24*60*5,24*60*7,24*60*10,24*60*14,24*60*17,24*60*21,24*60*24,24*60*28,24*60*35,24*60*42,24*60*49]\n",
    "for c in tqdm(['user_id','app_code','NearestLog_item_id_0']):\n",
    "    consol = getImpressionCounts(consol,c)\n",
    "    consol = getCountinLastDMins(consol,c,D=D)\n",
    "    print(consol.tail())\n",
    "    \n",
    "train = consol.iloc[:train.shape[0]]\n",
    "test = consol.iloc[train.shape[0]:]\n",
    "train['is_click'] = target\n",
    "\n",
    "train.to_csv('trainLogMergeImpressionTimeStats.csv',index=False)\n",
    "test.to_csv('testLogMergeImpressionTimeStats.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v3 code ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('trainWithLogMergeApprox.csv')\n",
    "test = pd.read_csv('testWithLogMergeApprox.csv')\n",
    "train['impression_time'] = pd.to_datetime(train['impression_time'])\n",
    "test['impression_time'] = pd.to_datetime(test['impression_time'])\n",
    "display(train.head(),test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### does not assume that no two time periods for the same \n",
    "\n",
    "def getRRByCategory(train,test,category,dvalueDiff,trace=False,limit=True):\n",
    "    print(\"Category:{}\".format(category))\n",
    "    if limit:\n",
    "        LL = limit\n",
    "    else:\n",
    "        LL = 'NoLimit'\n",
    "        dvalueDiff = 0\n",
    "        \n",
    "    train['BeforeRunRate_{}_{}_{}'.format(category,LL,dvalueDiff)] = -999\n",
    "    test['BeforeRunRate_{}_{}_{}'.format(category,LL,dvalueDiff)] = -999\n",
    "    testMiss = [] ### for things that are not in test\n",
    "    if trace:\n",
    "            pdb.set_trace()\n",
    "    for _uq in tqdm_notebook(train[category].unique()):\n",
    "        _i = train[train[category]==_uq].index\n",
    "        _i1 = test[test[category]==_uq].index\n",
    "        _tt =  train.loc[_i,'impression_time']\n",
    "        _tt1 = test.loc[_i1,'impression_time']\n",
    "        #print(\"Starting test loop\")\n",
    "        for time in np.unique(_tt1.values):\n",
    "            if limit:\n",
    "                dd = pd.to_datetime(time).day\n",
    "                increment = dd-12\n",
    "                diff = pd.to_datetime(time)-timedelta(days=dvalueDiff+increment)\n",
    "                IdxBool = (_tt>=diff) & (_tt<time)\n",
    "            else:\n",
    "                #print(\"aaaa\")\n",
    "                IdxBool = (_tt<time)\n",
    " \n",
    "            IdxBoolffill = _tt1[_tt1==time].index\n",
    "            \n",
    "            try:\n",
    "                sub = _tt[IdxBool]\n",
    "                meanRRBefore = train.loc[sub.index,'is_click'].mean()\n",
    "                if np.isnan(meanRRBefore):\n",
    "                    meanRRBefore = -999\n",
    "                test.loc[IdxBoolffill,'BeforeRunRate_{}_{}_{}'.format(category,LL,dvalueDiff)] = meanRRBefore            \n",
    "            except:\n",
    "                meanRRBefore = -999\n",
    "                test.loc[IdxBoolffill,'BeforeRunRate_{}_{}_{}'.format(category,LL,dvalueDiff)] = meanRRBefore        \n",
    "                testMiss.append(_uq)\n",
    "        #print(\"Starting train loop\")\n",
    "        for time in np.unique(_tt.values):\n",
    "            if limit:\n",
    "                diff = pd.to_datetime(time)-timedelta(days=dvalueDiff)\n",
    "                IdxBool = (_tt>=diff) & (_tt<time)\n",
    "            else:\n",
    "                IdxBool = (_tt<time)\n",
    " \n",
    "            IdxBoolffill = _tt[_tt==time].index\n",
    "            try:\n",
    "                sub = _tt[IdxBool]\n",
    "                meanRRBefore = train.loc[sub.index,'is_click'].mean()\n",
    "                if np.isnan(meanRRBefore):\n",
    "                    meanRRBefore = -999\n",
    "            except:\n",
    "                meanRRBefore = -999\n",
    "                testMiss.append(_uq)\n",
    "            train.loc[IdxBoolffill,'BeforeRunRate_{}_{}_{}'.format(category,LL,dvalueDiff)] = meanRRBefore\n",
    "        #print(\"-------\")\n",
    "    return train,test,testMiss\n",
    "train['app_code_NearestLog_item_id_0']= train['app_code'].astype(str)+\"_\"+train['NearestLog_item_id_0'].astype(str)\n",
    "test['app_code_NearestLog_item_id_0']= test['app_code'].astype(str)+\"_\"+test['NearestLog_item_id_0'].astype(str)\n",
    "for values in tqdm_notebook(['NearestLog_item_id_0','app_code_NearestLog_item_id_0']):\n",
    "    train,test,testMissFinal = getRRByCategory(train,test,values,dvalueDiff=1,trace=False,limit=False)\n",
    "    train,test,testMissFinal = getRRByCategory(train,test,values,dvalueDiff=7,trace=False,limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"trainWithRRstats_v3.csv\",index=False)\n",
    "test.to_csv(\"testWithRRstats_v3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LibFM code ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('trainWithLogMergeApprox.csv')\n",
    "test = pd.read_csv('testWithLogMergeApprox.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import mlcrate as mlc\n",
    "import pickle as pkl\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Embedding, Dense, Flatten, Concatenate, Dot, Reshape, Add, Subtract\n",
    "from keras import objectives\n",
    "from keras import backend as K\n",
    "from keras import regularizers \n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "\n",
    "# The below is necessary in Python 3.2.3 onwards to\n",
    "# have reproducible behavior for certain hash-based operations.\n",
    "# See these references for further details:\n",
    "# https://docs.python.org/3.4/using/cmdline.html#envvar-PYTHONHASHSEED\n",
    "# https://github.com/fchollet/keras/issues/2280#issuecomment-306959926\n",
    "\n",
    "import os\n",
    "\n",
    "def init_seeds(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "    # The below is necessary for starting Numpy generated random numbers\n",
    "    # in a well-defined initial state.\n",
    "\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # The below is necessary for starting core Python generated random numbers\n",
    "    # in a well-defined state.\n",
    "\n",
    "    rn.seed(seed)\n",
    "\n",
    "    # Force TensorFlow to use single thread.\n",
    "    # Multiple threads are a potential source of\n",
    "    # non-reproducible results.\n",
    "    # For further details, see: https://stackoverflow.com/questions/42022950/which-seeds-have-to-be-set-where-to-realize-100-reproducibility-of-training-res\n",
    "\n",
    "    session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "    from keras import backend as K\n",
    "\n",
    "    # The below tf.set_random_seed() will make random number generation\n",
    "    # in the TensorFlow backend have a well-defined initial state.\n",
    "    # For further details, see: https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n",
    "\n",
    "    tf.set_random_seed(seed)\n",
    "\n",
    "    sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "    K.set_session(sess)\n",
    "    return sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = ['NearestLog_device_type_0', 'app_code','NearestLog_item_id_0','impression_id']\n",
    "data = pd.concat([train[v],test[v]],0)\n",
    "data.head()\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le1 = LabelEncoder()\n",
    "le1.fit(data['NearestLog_device_type_0'].astype('str'))\n",
    "data['NearestLog_device_type_0_le']=le1.transform(data['NearestLog_device_type_0'].astype('str'))\n",
    "\n",
    "features = ['NearestLog_device_type_0_le', 'app_code','NearestLog_item_id_0']\n",
    "f_size  = [int(data[f].max()) + 1 for f in features]\n",
    "X = data.groupby(features)['impression_id'].count()\n",
    "X = X.unstack().fillna(0)\n",
    "X = X.stack().astype('float32')\n",
    "X = np.log1p(X).reset_index()\n",
    "X.columns=features + ['num']\n",
    "\n",
    "X_train = [X[f].values for f in features]\n",
    "y_train = (X[['num']].values).astype('float32')\n",
    "(X.num > 0).mean()\n",
    "w_train = (50 * (y_train > 0).astype('float32') + 1).ravel()\n",
    "k_latent = 2\n",
    "embedding_reg = 0.0002\n",
    "kernel_reg = 0.1\n",
    "\n",
    "def get_embed(x_input, x_size, k_latent):\n",
    "    if x_size > 0: #category\n",
    "        embed = Embedding(x_size, k_latent, input_length=1, \n",
    "                          embeddings_regularizer=l2(embedding_reg))(x_input)\n",
    "        embed = Flatten()(embed)\n",
    "    else:\n",
    "        embed = Dense(k_latent, kernel_regularizer=l2(embedding_reg))(x_input)\n",
    "    return embed\n",
    "\n",
    "def build_model_1(X, f_size):\n",
    "    dim_input = len(f_size)\n",
    "    \n",
    "    input_x = [Input(shape=(1,)) for i in range(dim_input)] \n",
    "     \n",
    "    biases = [get_embed(x, size, 1) for (x, size) in zip(input_x, f_size)]\n",
    "    \n",
    "    factors = [get_embed(x, size, k_latent) for (x, size) in zip(input_x, f_size)]\n",
    "    \n",
    "    s = Add()(factors)\n",
    "    \n",
    "    diffs = [Subtract()([s, x]) for x in factors]\n",
    "    \n",
    "    dots = [Dot(axes=1)([d, x]) for d,x in zip(diffs, factors)]\n",
    "    \n",
    "    x = Concatenate()(biases + dots)\n",
    "    x = BatchNormalization()(x)\n",
    "    output = Dense(1, activation='relu', kernel_regularizer=l2(kernel_reg))(x)\n",
    "    model = Model(inputs=input_x, outputs=[output])\n",
    "    opt = Adam(clipnorm=0.5)\n",
    "    model.compile(optimizer=opt, loss='mean_squared_error')\n",
    "    output_f = factors + biases\n",
    "    model_features = Model(inputs=input_x, outputs=output_f)\n",
    "    return model, model_features\n",
    "model, model_features = build_model_1(X_train, f_size)\n",
    "\n",
    "n_epochs = 100\n",
    "P = 17\n",
    "try:\n",
    "    del sess\n",
    "except:\n",
    "    pass\n",
    "sess = init_seeds(0)\n",
    "\n",
    "batch_size = 2**P\n",
    "print(batch_size)\n",
    "model, model_features = build_model_1(X_train, f_size)\n",
    "earlystopper = EarlyStopping(patience=0, verbose=1)\n",
    "\n",
    "model.fit(X_train,  y_train, \n",
    "          epochs=n_epochs, batch_size=batch_size, verbose=1, shuffle=True, \n",
    "          validation_data=(X_train, y_train), \n",
    "          sample_weight=w_train,\n",
    "          callbacks=[earlystopper],\n",
    "         )\n",
    "X_pred = model_features.predict(X_train, batch_size=batch_size)\n",
    "factors = X_pred[:len(features)]\n",
    "\n",
    "biases = X_pred[len(features):2*len(features)]\n",
    "\n",
    "for f, X_p in zip(features, factors):\n",
    "    for i in range(k_latent):\n",
    "        X['%s_fm_factor_%d' % (f, i)] = X_p[:,i]\n",
    "\n",
    "for f, X_p in zip(features, biases):\n",
    "    X['%s_fm_bias' % (f)] = X_p[:,0]\n",
    "\n",
    "\n",
    "X['NearestLog_device_type_0_le'] = np.array(le1.inverse_transform(np.array(X['NearestLog_device_type_0_le'])))\n",
    "X.to_csv('FM_feats.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consol v0 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_0 = pd.read_csv('trainWithRRstats_v0.csv')\n",
    "test_0 = pd.read_csv('testWithRRstats_v0.csv')\n",
    "\n",
    "train_1 = pd.read_csv('trainWithRRstats_v1.csv')\n",
    "test_1 = pd.read_csv('testWithRRstats_v1.csv')\n",
    "\n",
    "cols_1=['app_code_os_version','BeforeRunRate_app_code_os_version_NoLimit_0',\n",
    "       'BeforeRunRate_user_id_app_code_NoLimit_0']\n",
    "train_consol = pd.concat([train_0,train_1[cols_1]],1)\n",
    "test_consol = pd.concat([test_0,test_1[cols_1]],1)\n",
    "del train_1,test_1,train_0,test_0\n",
    "\n",
    "train_2 = pd.read_csv('trainWithRRstats_v2.csv')\n",
    "test_2 = pd.read_csv('testWithRRstats_v2.csv')\n",
    "cols_2 = ['user_id_app_code','BeforeRunRate_app_code_os_version_NoLimit_0']\n",
    "train_consol = pd.concat([train_consol,train_2[cols_2]],1)\n",
    "test_consol = pd.concat([test_consol,test_2[cols_2]],1)\n",
    "del train_2,test_2\n",
    "\n",
    "train_3 = pd.read_csv('trainWithRRstats_v3.csv')\n",
    "test_3 = pd.read_csv('testWithRRstats_v3.csv')\n",
    "keep = [i for i in test_3.columns if i in train_3.columns]\n",
    "train_3 = train_3[keep]\n",
    "cols_3=[i for i in train_3.columns if i not in train_consol.columns]\n",
    "train_consol = pd.concat([train_consol,train_3[cols_3]],1)\n",
    "test_consol = pd.concat([test_consol,test_3[cols_3]],1)\n",
    "del train_3,test_3\n",
    "\n",
    "train_consol['impression_weekday']=pd.to_datetime(train_consol['impression_time']).dt.weekday\n",
    "test_consol['impression_weekday']=pd.to_datetime(test_consol['impression_time']).dt.weekday\n",
    "train_consol.loc[train_consol['NearestLog_server_time']=='0','NearestLog_server_time'] = pd.to_datetime('2018-01-01 00:00:00')\n",
    "test_consol.loc[test_consol['NearestLog_server_time']=='0','NearestLog_server_time'] = pd.to_datetime('2018-01-01 00:00:00')\n",
    "train_consol['NearestLog_server_time_weekday']=pd.to_datetime(train_consol['NearestLog_server_time']).dt.weekday\n",
    "test_consol['NearestLog_server_time_weekday']=pd.to_datetime(test_consol['NearestLog_server_time']).dt.weekday\n",
    "train_consol['NearestLog_server_time_day']=pd.to_datetime(train_consol['NearestLog_server_time']).dt.day\n",
    "test_consol['NearestLog_server_time_day']=pd.to_datetime(test_consol['NearestLog_server_time']).dt.day\n",
    "train_consol['NearestLog_server_time_month']=pd.to_datetime(train_consol['NearestLog_server_time']).dt.month\n",
    "test_consol['NearestLog_server_time_month']=pd.to_datetime(test_consol['NearestLog_server_time']).dt.month\n",
    "train_consol['NearestLog_server_time_hour']=pd.to_datetime(train_consol['NearestLog_server_time']).dt.hour\n",
    "test_consol['NearestLog_server_time_hour']=pd.to_datetime(test_consol['NearestLog_server_time']).dt.hour\n",
    "train_4 = pd.read_csv('trainLogMergeImpressionTimeStats.csv')\n",
    "test_4 = pd.read_csv('testLogMergeImpressionTimeStats.csv')\n",
    "c = [i for i in train_4.columns if i not in train_consol.columns]\n",
    "\n",
    "train_consol = pd.concat([train_consol,train_4[c]],1)\n",
    "test_consol = pd.concat([test_consol,test_4[c]],1)\n",
    "\n",
    "#ls '../input/av-wns-hack/train_na17sgz/'\n",
    "log = pd.read_csv('../input/av-wns-hack/train_na17sgz/view_log.csv')\n",
    "item = pd.read_csv('../input/av-wns-hack/train_na17sgz/item_data.csv')\n",
    "\n",
    "train_consol.replace(-999.0, 0,inplace=True)\n",
    "test_consol.replace(-999.0, 0,inplace=True)\n",
    "\n",
    "train_consol.fillna(-99,inplace=True)\n",
    "test_consol.fillna(-99,inplace=True)\n",
    "\n",
    "itemIdCols = ['NearestLog_item_id_0','NearestLog_item_id_1','NearestLog_item_id_2','NearestLog_item_id_3',\n",
    "             'NearestLog_item_id_4','NearestLog_item_id_5','NearestLog_item_id_6','NearestLog_item_id_7']\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "import pdb\n",
    "neigh = 0\n",
    "for c in tqdm_notebook(itemIdCols):\n",
    "    Ttemp = pd.merge(train_consol[c],item,left_on=c,right_on='item_id',how='left')\n",
    "    Ttemp.drop([c,'item_id'],1,inplace=True)\n",
    "    columnName = Ttemp.columns\n",
    "    newNames = [i+\"_\"+str(neigh) for i in columnName]\n",
    "    dc = dict(zip(columnName,newNames))\n",
    "    Ttemp.rename(columns=dc,inplace=True)\n",
    "    Tetemp = pd.merge(test_consol[c],item,left_on=c,right_on='item_id',how='left')\n",
    "    Tetemp.drop([c,'item_id'],1,inplace=True)\n",
    "    Tetemp.rename(columns=dc,inplace=True)\n",
    "    train_consol = pd.concat([train_consol,Ttemp],1)\n",
    "    test_consol = pd.concat([test_consol,Tetemp],1)\n",
    "    neigh += 1\n",
    "\n",
    "train_consol.fillna(-99,inplace=True)\n",
    "test_consol.fillna(-99,inplace=True)\n",
    "\n",
    "target = train_consol['is_click']\n",
    "train_consol.drop('is_click',1,inplace=True)\n",
    "v = ['os_version', 'NearestLog_device_type_0', 'app_code','NearestLog_item_id_0','impression_id']\n",
    "consol = pd.concat([train_consol,test_consol],0)\n",
    "\n",
    "def newCountStats(df,v1,train,test,cname):  ### df = consol\n",
    "    X = df.groupby(v1)['impression_id'].count()\n",
    "    X = X.unstack().fillna(0)\n",
    "    X = X.stack().astype('float32')\n",
    "    X = np.log1p(X).reset_index()\n",
    "    X.columns=v1 + [cname]\n",
    "    train = pd.merge(train,X,on=v1,how='left')\n",
    "    test = pd.merge(test,X,on=v1,how='left')\n",
    "    train.fillna(0,inplace=True)\n",
    "    test.fillna(0,inplace=True)\n",
    "    return train,test\n",
    "v1 = ['os_version', 'NearestLog_device_type_0', 'app_code','NearestLog_item_id_0']\n",
    "v2 = ['user_id', 'app_code']\n",
    "v3 = ['NearestLog_device_type_0', 'app_code']\n",
    "v4 = ['NearestLog_device_type_0', 'app_code','NearestLog_device_type_1']\n",
    "v5 = ['NearestLog_device_type_0', 'user_id','app_code']\n",
    "\n",
    "count  = 1\n",
    "for vs in tqdm_notebook([v1,v2,v3,v4,v5]):\n",
    "    name = \"num_{}\".format(count) \n",
    "    train_consol,test_consol = newCountStats(consol,vs,train_consol,test_consol,name)\n",
    "    count += 1\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "def do_countuniq( df, group_cols, counted, agg_type='uint8', show_max=False, show_agg=True ):\n",
    "    agg_name= '{}_by_{}_countuniq'.format(('_'.join(group_cols)),(counted))  \n",
    "    if show_agg:\n",
    "        print( \"\\nCounting unqiue \", counted, \" by \", group_cols ,  '... and saved in', agg_name )\n",
    "    gp = df[group_cols+[counted]].groupby(group_cols)[counted].nunique().reset_index().rename(columns={counted:agg_name})\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type)\n",
    "    gc.collect()\n",
    "    return( df )\n",
    "### Below a function is written to extract cumulative count feature  from different cols    \n",
    "def do_cumcount( df, group_cols, counted,agg_type='uint16', show_max=False, show_agg=True ):\n",
    "    agg_name= '{}_by_{}_cumcount'.format(('_'.join(group_cols)),(counted)) \n",
    "    if show_agg:\n",
    "        print( \"\\nCumulative count by \", group_cols , '... and saved in', agg_name  )\n",
    "    gp = df[group_cols+[counted]].groupby(group_cols)[counted].cumcount()\n",
    "    df[agg_name]=gp.values\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type)\n",
    "    gc.collect()\n",
    "    return( df )\n",
    "## Below a function is written to extract count feature by aggregating different cols\n",
    "def do_count( df, group_cols, agg_type='uint16', show_max=False, show_agg=True ):\n",
    "    agg_name='{}count'.format('_'.join(group_cols))  \n",
    "    if show_agg:\n",
    "        print( \"\\nAggregating by \", group_cols ,  '... and saved in', agg_name )\n",
    "    gp = df[group_cols][group_cols].groupby(group_cols).size().rename(agg_name).to_frame().reset_index()\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type)\n",
    "    gc.collect()\n",
    "    return( df )\n",
    "train_consol['impression_time_hour']=pd.to_datetime(train_consol['impression_time']).dt.hour\n",
    "test_consol['impression_time_hour']=pd.to_datetime(test_consol['impression_time']).dt.hour\n",
    "train_consol['impression_time_month']=pd.to_datetime(train_consol['impression_time']).dt.month\n",
    "test_consol['impression_time_month']=pd.to_datetime(test_consol['impression_time']).dt.month\n",
    "\n",
    "train_df = train_consol.copy()\n",
    "cols = [i for i in train_df.columns if i in test_consol.columns]\n",
    "len_train = len(train_df)\n",
    "train_df=train_df[cols].append(test_consol[cols])\n",
    "train_df.reset_index(drop=True,inplace=True)\n",
    "#del test\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "train_df = do_countuniq( train_df, ['user_id'], 'os_version' ); gc.collect()\n",
    "train_df = do_countuniq( train_df, ['user_id', 'NearestLog_device_type_0', 'os_version'], 'app_code'); gc.collect()\n",
    "train_df = do_countuniq( train_df, ['user_id', 'impression_time_day'], 'impression_time_hour' ); gc.collect()\n",
    "train_df = do_countuniq( train_df, ['user_id'], 'app_code'); gc.collect()\n",
    "train_df = do_countuniq( train_df, ['user_id', 'app_code'], 'os_version'); gc.collect()\n",
    "train_df = do_countuniq( train_df, ['user_id'], 'NearestLog_device_type_0'); gc.collect()\n",
    "train_df = do_countuniq( train_df, ['app_code'], 'os_version'); gc.collect()\n",
    "\n",
    "train_df = do_cumcount( train_df, ['user_id'], 'os_version'); gc.collect()\n",
    "train_df = do_cumcount( train_df, ['user_id', 'NearestLog_device_type_0', 'os_version'], 'app_code'); gc.collect()\n",
    "train_df = do_count( train_df, ['user_id', 'impression_time_day', 'impression_time_hour'] ); gc.collect()\n",
    "train_df = do_count( train_df, ['user_id', 'app_code']); gc.collect()\n",
    "train_df = do_count( train_df, ['user_id', 'app_code', 'os_version']); gc.collect()\n",
    "\n",
    "# FMFeats = pd.read_csv('FM_feats.csv')\n",
    "\n",
    "# train_df = pd.merge(train_df,FMFeats,left_on=['NearestLog_device_type_0','app_code','NearestLog_item_id_0']\n",
    "#                     ,right_on=['NearestLog_device_type_0_le','app_code','NearestLog_item_id_0'],how='left')\n",
    "\n",
    "# train_df.drop('NearestLog_device_type_0_le',1,inplace=True)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "cats = ['app_code','os_version','is_4G','app_code_NearestLog_item_id_0','app_code_os_version',\n",
    "        'user_id_app_code','NearestLog_device_type_0','NearestLog_device_type_1', \n",
    "        'NearestLog_device_type_2',\n",
    "         'NearestLog_device_type_3','NearestLog_device_type_4', 'NearestLog_device_type_5',\n",
    "         'NearestLog_device_type_6', 'NearestLog_device_type_7',\n",
    "       'NearestLog_item_id_0', 'NearestLog_item_id_1', 'NearestLog_item_id_2','NearestLog_item_id_3',\n",
    "        'NearestLog_item_id_4','NearestLog_item_id_5','NearestLog_item_id_6', 'NearestLog_item_id_7',        \n",
    "        'impression_weekday','NearestLog_server_time_weekday']\n",
    "categoryID = [i for i in train_consol.columns if 'category_' in i]\n",
    "pdtID = [i for i in train_consol.columns if 'product_type_' in i]\n",
    "\n",
    "cats = cats+categoryID+pdtID\n",
    "for j in tqdm_notebook(cats):\n",
    "    print(j)\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    train_df[j] = train_df[j].astype('str')\n",
    "    train_df[j] = le.fit_transform(train_df[j])\n",
    "    \n",
    "train_consol = train_df.iloc[:train_consol.shape[0],:]\n",
    "test_consol = train_df.iloc[train_consol.shape[0]:,:]\n",
    "\n",
    "train_consol.fillna(-99,inplace=True)\n",
    "test_consol.fillna(-99,inplace=True)\n",
    "\n",
    "drop = ['impression_time','user_id','NearestLog_server_time','NearestLog_user_id']\n",
    "train_consol['is_click'] = target\n",
    "train_consol.drop(drop,1,inplace=True)\n",
    "test_consol.drop(drop,1,inplace=True)\n",
    "\n",
    "train_consol.to_csv('consolTrain.csv',index=False)\n",
    "test_consol.to_csv('consolTest.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Start here for this lgbm ###### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('consolTrain.csv')\n",
    "test = pd.read_csv('consolTest.csv')\n",
    "\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',10000)\n",
    "import seaborn as sns\n",
    "import gc\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "from datetime import datetime\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(tag_name):\n",
    "    import datetime\n",
    "    def timer_decorator(fn):\n",
    "        def _fn(*args, **kwargs):\n",
    "            s = datetime.datetime.now()\n",
    "            output = fn(*args, **kwargs)\n",
    "            e = datetime.datetime.now()\n",
    "            print('[{}] {} completed in {}'.format(tag_name, fn.__name__, e - s))\n",
    "            return output\n",
    "\n",
    "        return _fn\n",
    "\n",
    "    return timer_decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc,roc_curve,roc_auc_score\n",
    "def aucROC(y_pred,dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'AUC:',roc_auc_score(np.array(labels), np.array(y_pred)),True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timer('KFoldLGBModel')\n",
    "def runLGBMWithKF(train,test,Y,param,splits,cats,stratified=True):\n",
    "    from sklearn.model_selection import StratifiedKFold,KFold\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits=splits, shuffle=True, random_state=123)\n",
    "    else:\n",
    "        folds = KFold(n_splits=splits, shuffle=True, random_state=123)\n",
    "    oof_preds = np.zeros(train.shape[0])\n",
    "    sub_preds = np.zeros(test.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()    \n",
    "    for n_fold, (trn_idx, val_idx) in enumerate(folds.split(train,Y)):\n",
    "        trn_x, trn_y = train.iloc[trn_idx], Y.iloc[trn_idx]\n",
    "        val_x, val_y = train.iloc[val_idx], Y.iloc[val_idx]\n",
    "        \n",
    "        xg_train = lgb.Dataset(trn_x,\n",
    "                               label=trn_y,\n",
    "                               free_raw_data = False\n",
    "                               )\n",
    "        xg_valid = lgb.Dataset(val_x,\n",
    "                               label=val_y,\n",
    "                               free_raw_data = False\n",
    "                               )   \n",
    "\n",
    "        print(\"Fold:\",n_fold+1)\n",
    "        clf = lgb.train(param, xg_train, 10000, valid_sets = [xg_train,xg_valid], \n",
    "                        verbose_eval=100, early_stopping_rounds = 500,\n",
    "                        feval= aucROC,  categorical_feature=cats)\n",
    "\n",
    "        oof_preds[val_idx] = clf.predict(val_x, num_iteration=clf.best_iteration)\n",
    "        sub_preds += clf.predict(test, num_iteration=clf.best_iteration)/folds.n_splits\n",
    "        print('Val AUC : %.6f' % roc_auc_score(val_y,oof_preds[val_idx]))\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = train.columns\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "        fold_importance_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        gc.collect()\n",
    "    print(\"Full AUC:\",roc_auc_score(Y,oof_preds))\n",
    "    return feature_importance_df,sub_preds,oof_preds,roc_auc_score(Y,oof_preds)\n",
    "### below give 71.9 on lb, not anymore\n",
    "params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "       'metric':'auc',\n",
    "        'learning_rate': 0.008,\n",
    "        'is_unbalance': 'false',  #because training data is unbalance (replaced with scale_pos_weight)\n",
    "        'num_leaves': 11,  # we should let it be smaller than 2^(max_depth)\n",
    "        'max_depth': 6,  # -1 means no limit\n",
    "        'min_child_samples': 35,  # Minimum number of data need in a child(min_data_in_leaf)\n",
    "        #'bagging_fraction':0.9429,\n",
    "        'max_bin': 255,  # Number of bucketed bin for feature values\n",
    "        'subsample': 0.2,  # Subsample ratio of the training instance.\n",
    "       #'subsample_freq': 0.5,  # frequence of subsample, <=0 means no enable\n",
    "        'feature_fraction': 0.2,  # Subsample ratio of columns when constructing each tree.\n",
    "        'min_child_weight': 51.76,  # Minimum sum of instance weight(hessian) needed in a child(leaf)\n",
    "        'min_split_gain': 0.07,  # lambda_l1, lambda_l2 and min_gain_to_split to regularization\n",
    "        'reg_alpha': 1.43,  # L1 regularization term on weights\n",
    "        'reg_lambda': 8.33,  # L2 regularization term on weights\n",
    "        'nthread': 8,\n",
    "        'verbose': 0,\n",
    "        'random_state':42\n",
    "    }\n",
    "newTrain = train.drop(['is_click','impression_id'],1)\n",
    "newTest = test.drop('impression_id',1)\n",
    "target = train['is_click']\n",
    "feature_importance_df_lgbm,sub_preds_lgbm,oof_preds_lgbm,CV_lgbm = runLGBMWithKF(newTrain,newTest,target,params,12,'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writefiles(model,CV,sub_preds,feature_importance_df=None):\n",
    "    CV = str(CV)\n",
    "    name = model+\"_submit_\"+CV+\".csv\"\n",
    "    name1 = model+\"_featImp_\"+CV+\".csv\"\n",
    "    sample_submit = pd.DataFrame()\n",
    "    sample_submit['impression_id'] = test['impression_id']\n",
    "    sample_submit['is_click'] = sub_preds\n",
    "    sample_submit.to_csv('lgbm-0.747867710652706.csv',index=False)\n",
    "    if feature_importance_df is not None:\n",
    "        feature_importance_df.to_csv(name1,index=False)\n",
    "writefiles('lgbm12Fold',CV_lgbm,sub_preds_lgbm,feature_importance_df=feature_importance_df_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink, FileLinks\n",
    "FileLinks('.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
